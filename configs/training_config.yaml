# Training Configuration
model:
  width: 32           # Number of neurons per hidden layer
  layers: 8           # Number of dense hidden layers
  activation: 'relu'  # Activation function for hidden layers
  output_activation: 'sigmoid' # Activation function for output layer

training:
  epochs: 10
  batch_size: 32
  learning_rate: 0.001
  decay_coeff: 0.1    # Learning rate decay coefficient
  early_stopping_patience: 75 # Number of epochs with no improvement after which training will be stopped
  device: 'cpu'      # Training device: 'auto', 'cpu', 'cuda', 'mps'
  seed: 42            # Random seed for PyTorch and NumPy for reproducible training runs
  parallel:
    total_models: 1  # Total number of models to train
    max_parallel_ratio: 0.75  # Maximum ratio of CPU cores to use (0.0 to 1.0)
    min_parallel_models: 1    # Minimum number of models to train in parallel
    max_parallel_models: 8    # Maximum number of models to train in parallel
    save_threshold: 0.6  # Accuracy threshold for saving models

data:
  test_size: 0.2      # Proportion of the dataset to include in the test split
  random_seed: 52     # Random seed for data splitting (e.g., train_test_split)
  generation:
    n: 200           # Number of data points to generate
    big_radius: 3     # Radius of the larger circle of the torus
    small_radius: 1   # Radius of the smaller circle (tube) of the torus
